{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f68a37e3-80d4-4121-b474-03bca206a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from questions import answer_question\n",
    "from telegram import Update\n",
    "from telegram.ext import ContextTypes, CommandHandler, ApplicationBuilder, MessageHandler, filters\n",
    "from openai import OpenAI\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ec714c9-ad1e-4b34-9bd1-52519dcccab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import functions, run_function\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f989080-5890-4eb8-b71c-a7c6f2a17e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_PROMPT = \"\"\"\n",
    "Here are two input:output examples for code generation. Please use these and follow the styling for future requests that you think are pertinent to the request.\n",
    "Make sure All HTML is generated with the JSX flavoring.\n",
    "// SAMPLE 1\n",
    "// A Blue Box with 3 yellow cirles inside of it that have a red outline\n",
    "<div style={{   backgroundColor: 'blue',\n",
    "  padding: '20px',\n",
    "  display: 'flex',\n",
    "  justifyContent: 'space-around',\n",
    "  alignItems: 'center',\n",
    "  width: '300px',\n",
    "  height: '100px', }}>\n",
    "  <div style={{     backgroundColor: 'yellow',\n",
    "    borderRadius: '50%',\n",
    "    width: '50px',\n",
    "    height: '50px',\n",
    "    border: '2px solid red'\n",
    "  }}></div>\n",
    "  <div style={{     backgroundColor: 'yellow',\n",
    "    borderRadius: '50%',\n",
    "    width: '50px',\n",
    "    height: '50px',\n",
    "    border: '2px solid red'\n",
    "  }}></div>\n",
    "  <div style={{     backgroundColor: 'yellow',\n",
    "    borderRadius: '50%',\n",
    "    width: '50px',\n",
    "    height: '50px',\n",
    "    border: '2px solid red'\n",
    "  }}></div>\n",
    "</div>\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fdb0988-4eb7-4536-8993-79ce0fced630",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bfc89b0-de9d-4231-b51e-9fafb5351b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed/embeddings.csv', index_col=0)\n",
    "df['embeddings'] = df['embeddings'].apply(eval).apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7bfa6885-63f3-4445-b7d8-8403ad20f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "tg_bot_token = os.environ['TG_BOT_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09c11a95-f827-4be8-a0f6-28fd4e05d90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 15:00:47,996 - httpx - $(levelname)s - HTTP Request: POST https://api.openai.com/v1/assistants \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "assistant = openai.beta.assistants.create(\n",
    "    name=\"Telegram Bot\",\n",
    "    instructions=CODE_PROMPT,\n",
    "    tools=[\n",
    "    {\"type\": \"code_interpreter\"},\n",
    "    ],\n",
    "    model=\"gpt-4-0125-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7885563b-f958-42a6-8302-7940b039c894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 15:00:48,391 - httpx - $(levelname)s - HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "THREAD = openai.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d18ffbfc-7036-46d8-aac2-7e846dbcb03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(name)s - $(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "707fd083-53f1-4cba-afa2-a37061eb9495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_on_run(run, thread):\n",
    "    while run.status in (\"queued\", \"in_progress\"):\n",
    "        print(run.status)\n",
    "        run = openai.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id,\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19921c02-574c-4f88-b551-f2ae2e5a34e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def assistant_chat(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    message = openai.beta.threads.messages.create(\n",
    "    thread_id=THREAD.id, role=\"user\", content=update.message.text\n",
    "    )\n",
    "    run = openai.beta.threads.runs.create(\n",
    "    thread_id=THREAD.id, assistant_id=assistant.id\n",
    "    )\n",
    "    run = wait_on_run(run, THREAD)\n",
    "    # Grab all of our message history\n",
    "    messages = openai.beta.threads.messages.list(\n",
    "    thread_id=THREAD.id, order=\"asc\", after=message.id\n",
    "    )\n",
    "    # Extract the message content\n",
    "    message_content = messages.data[0].content[0].text\n",
    "    await context.bot.send_message(\n",
    "    chat_id=update.effective_chat.id, text=message_content.value\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93271b66-6b2f-4c69-a579-8eb2eac961ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def mozilla(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    answer = answer_question(df, question=update.message.text, debug=True)\n",
    "    await context.bot.send_message(chat_id=update.effective_chat.id, text=answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad7f3ba2-5af0-4d34-9119-f4c69f6cde3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    await context.bot.send_message(chat_id=update.effective_chat.id,\n",
    "                                  text=\"I am a bot, please talk to me.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "469a47fb-88ab-4580-87bc-baa63fcd4141",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def image(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    response = openai.images.generate(prompt=update.message.text,\n",
    "                                    model=\"dall-e-3\",\n",
    "                                    n=1,\n",
    "                                    size=\"1024x1024\")\n",
    "    image_url = response.data[0].url\n",
    "    image_response = requests.get(image_url)\n",
    "    await context.bot.send_photo(chat_id=update.effective_chat.id,\n",
    "                               photo=image_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fed198b2-54a3-45d2-832b-7e69ac2bf161",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def transcribe_message(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    # Make sure we have a voice file to transcribe\n",
    "    voice_id = update.message.voice.file_id\n",
    "    if voice_id:\n",
    "        file = await context.bot.get_file(voice_id)\n",
    "        await file.download_to_drive(f\"voice_note_{voice_id}.ogg\")\n",
    "        await update.message.reply_text(\"Voice note downloaded, transcribing now\")\n",
    "        audio_file = open(f\"voice_note_{voice_id}.ogg\", \"rb\")\n",
    "        transcript = openai.audio.transcriptions.create(\n",
    "        model=\"whisper-1\", file=audio_file\n",
    "        )\n",
    "        messages.append({\"role\": \"user\", \"content\": transcript.text})\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages\n",
    "        )\n",
    "        # Feed it back into the LLM\n",
    "        response_message = response.choices[0].message\n",
    "        messages.append(response_message)\n",
    "        await update.message.reply_text(f\"Transcript finished:\\n{transcript.text}\")\n",
    "        await context.bot.send_message(chat_id=update.effective_chat.id, text=response_message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6b078c9-79e3-48e6-98e3-ad9f6f0cb86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to run the bot\n",
    "async def main() -> None:\n",
    "    application = ApplicationBuilder().token(tg_bot_token).build()\n",
    "\n",
    "    start_handler = CommandHandler('start', start)\n",
    "    chat_handler = MessageHandler(filters.TEXT & (~filters.COMMAND), assistant_chat)\n",
    "    image_handler = CommandHandler('image', image)\n",
    "    mozilla_handler = CommandHandler('mozilla', mozilla)\n",
    "    voice_handler = MessageHandler(filters.VOICE, transcribe_message)\n",
    "\n",
    "    application.add_handler(start_handler)\n",
    "    application.add_handler(chat_handler)\n",
    "    application.add_handler(image_handler)\n",
    "    application.add_handler(mozilla_handler)\n",
    "    application.add_handler(voice_handler)\n",
    "\n",
    "    await application.run_polling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abd047c-760e-4481-926d-8c27c67add88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 15:00:57,935 - httpx - $(levelname)s - HTTP Request: POST https://api.telegram.org/bot7387544315:AAEuwrT3P6dwQ6emRERUjFrp7a1XebcqY8o/getMe \"HTTP/1.1 200 OK\"\n",
      "2024-07-08 15:00:58,121 - httpx - $(levelname)s - HTTP Request: POST https://api.telegram.org/bot7387544315:AAEuwrT3P6dwQ6emRERUjFrp7a1XebcqY8o/deleteWebhook \"HTTP/1.1 200 OK\"\n",
      "2024-07-08 15:00:58,125 - apscheduler.scheduler - $(levelname)s - Scheduler started\n",
      "2024-07-08 15:00:58,126 - telegram.ext.Application - $(levelname)s - Application started\n",
      "2024-07-08 15:01:07,562 - httpx - $(levelname)s - HTTP Request: POST https://api.telegram.org/bot7387544315:AAEuwrT3P6dwQ6emRERUjFrp7a1XebcqY8o/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2024-07-08 15:01:08,015 - httpx - $(levelname)s - HTTP Request: POST https://api.openai.com/v1/threads/thread_PWqHrb1j4MQzKzBxKtMhCUWf/messages \"HTTP/1.1 200 OK\"\n",
      "2024-07-08 15:01:08,668 - httpx - $(levelname)s - HTTP Request: POST https://api.openai.com/v1/threads/thread_PWqHrb1j4MQzKzBxKtMhCUWf/runs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queued\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 15:01:09,076 - httpx - $(levelname)s - HTTP Request: GET https://api.openai.com/v1/threads/thread_PWqHrb1j4MQzKzBxKtMhCUWf/runs/run_5WYKKCy6BB93kuQ2vaKF4n1o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 15:01:09,913 - httpx - $(levelname)s - HTTP Request: GET https://api.openai.com/v1/threads/thread_PWqHrb1j4MQzKzBxKtMhCUWf/runs/run_5WYKKCy6BB93kuQ2vaKF4n1o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 15:01:10,747 - httpx - $(levelname)s - HTTP Request: GET https://api.openai.com/v1/threads/thread_PWqHrb1j4MQzKzBxKtMhCUWf/runs/run_5WYKKCy6BB93kuQ2vaKF4n1o \"HTTP/1.1 200 OK\"\n",
      "2024-07-08 15:01:11,657 - httpx - $(levelname)s - HTTP Request: GET https://api.openai.com/v1/threads/thread_PWqHrb1j4MQzKzBxKtMhCUWf/messages?after=msg_HYkzwxFnNKJlAmVJjz4im5M0&order=asc \"HTTP/1.1 200 OK\"\n",
      "2024-07-08 15:01:12,507 - httpx - $(levelname)s - HTTP Request: POST https://api.telegram.org/bot7387544315:AAEuwrT3P6dwQ6emRERUjFrp7a1XebcqY8o/sendMessage \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Check if the script is run directly (not imported)\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        asyncio.run(main())\n",
    "    except RuntimeError as e:\n",
    "        if str(e) == \"asyncio.run() cannot be called from a running event loop\":\n",
    "            loop = asyncio.get_event_loop()\n",
    "            loop.run_until_complete(main())\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e15ac-88e4-4690-8298-bbd4d5af00d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
